Namespace(batch_size=500, bce_lambda=1.0, bec_p=0.0, bec_p_dec=0.0, ber_lambda=1.0, block_len=100, block_len_high=200, block_len_low=10, bsc_p=0.0, bsc_p_dec=0.0, channel='awgn', code_rate_k=1, code_rate_n=3, dec_act='linear', dec_kernel_size=5, dec_lr=0.0001, dec_num_layer=5, dec_num_unit=100, dec_rnn='gru', decoder='TurboAE_rate3_cnn', demod_lr=0.005, demod_num_layer=1, demod_num_unit=20, dropout=0.0, enc_act='elu', enc_clipping='both', enc_grad_limit=0.01, enc_kernel_size=5, enc_lr=0.0001, enc_num_layer=2, enc_num_unit=100, enc_quantize_level=2, enc_rnn='gru', enc_truncate_limit=0, enc_value_limit=1.0, encoder='TurboAE_rate3_cnn', extrinsic=1, focal_alpha=1.0, focal_gamma=0.0, img_size=10, init_nw_weight='./models/dta_cont_cnn2_cnn5_enctrain2_dectrainneg15_2.pt', is_interleave=1, is_k_same_code=False, is_parallel=1, is_same_interleaver=1, is_variable_block_len=False, joint_train=0, k_same_code=2, lambda_maxBCE=0.01, loss='bce', mod_lr=0.005, mod_num_layer=1, mod_num_unit=20, mod_pc='block_power', mod_rate=2, momentum=0.9, no_code_norm=False, no_cuda=False, num_ber_puncture=5, num_block=50000, num_epoch=0, num_iter_ft=5, num_iteration=6, num_train_dec=5, num_train_demod=5, num_train_enc=1, num_train_mod=1, optimizer='adam', precompute_norm_stats=False, print_pos_ber=False, print_pos_power=False, print_test_traj=True, radar_power=5.0, radar_prob=0.05, rec_quantize=False, rec_quantize_level=2, rec_quantize_limit=1.0, snr_points=29, snr_test_end=8.0, snr_test_start=-6.0, test_channel_mode='block_norm', test_ratio=1, train_channel_mode='block_norm', train_dec_channel_high=2.0, train_dec_channel_low=-1.5, train_enc_channel_high=2.0, train_enc_channel_low=2.0, vv=5)
using random interleaver [26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44] [18 29 64 92 72 87  5 15 12 17 61 76  9 78 80  7 33  6 37 74 79  1 45 28
 60 52 25 39 97 44 16 55 83 49 22 70 47  4 82 94 53 66 26 84 31 63  8 75
 98 57 71 99 86 96 69 24 30 13 40 56 68 95 81 19 38 91 54 32 51 85 11 89
 90 36 65 88 41 14 27 50 20 46 67 35 62  2 59 23 58 43 10  0 73 21 77 42
  3 93 48 34]
Channel_AE(
  (enc): ENC_interCNN(
    (enc_cnn_1): DataParallel(
      (module): SameShapeConv1d(
        (cnns): ModuleList(
          (0): Conv1d(1, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
        )
      )
    )
    (enc_cnn_2): DataParallel(
      (module): SameShapeConv1d(
        (cnns): ModuleList(
          (0): Conv1d(1, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
        )
      )
    )
    (enc_cnn_3): DataParallel(
      (module): SameShapeConv1d(
        (cnns): ModuleList(
          (0): Conv1d(1, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
        )
      )
    )
    (enc_linear_1): DataParallel(
      (module): Linear(in_features=100, out_features=1, bias=True)
    )
    (enc_linear_2): DataParallel(
      (module): Linear(in_features=100, out_features=1, bias=True)
    )
    (enc_linear_3): DataParallel(
      (module): Linear(in_features=100, out_features=1, bias=True)
    )
    (interleaver): Interleaver()
  )
  (dec): DEC_LargeCNN(
    (interleaver): Interleaver()
    (deinterleaver): DeInterleaver()
    (dec1_cnns): ModuleList(
      (0): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (1): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (2): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (3): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (4): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (5): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
    )
    (dec2_cnns): ModuleList(
      (0): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (1): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (2): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (3): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (4): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
      (5): DataParallel(
        (module): SameShapeConv1d(
          (cnns): ModuleList(
            (0): Conv1d(7, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (3): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
            (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,))
          )
        )
      )
    )
    (dec1_outputs): ModuleList(
      (0): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (1): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (2): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (3): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (4): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (5): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
    )
    (dec2_outputs): ModuleList(
      (0): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (1): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (2): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (3): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (4): DataParallel(
        (module): Linear(in_features=100, out_features=5, bias=True)
      )
      (5): DataParallel(
        (module): Linear(in_features=100, out_features=1, bias=True)
      )
    )
  )
)
test loss trajectory []
test ber trajectory []
total epoch 0
saved model ./tmp/torch_model_973267.pt
SNRS [-6.0, -5.5, -5.0, -4.5, -4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0]
no pos BER specified.
Test SNR -6.0 with ber  0.4193839132785797 with bler 1.0
Punctured Test SNR -6.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -5.5 with ber  0.4057748019695282 with bler 0.99996
Punctured Test SNR -5.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -5.0 with ber  0.3900512456893921 with bler 0.9998000000000001
Punctured Test SNR -5.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -4.5 with ber  0.36726969480514526 with bler 0.9993800000000003
Punctured Test SNR -4.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -4.0 with ber  0.3388248383998871 with bler 0.99664
Punctured Test SNR -4.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -3.5 with ber  0.3005545735359192 with bler 0.9879799999999999
Punctured Test SNR -3.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -3.0 with ber  0.2530718147754669 with bler 0.9665399999999995
Punctured Test SNR -3.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -2.5 with ber  0.19663816690444946 with bler 0.9137800000000007
Punctured Test SNR -2.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -2.0 with ber  0.1387261599302292 with bler 0.8149599999999999
Punctured Test SNR -2.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -1.5 with ber  0.0839385986328125 with bler 0.6616
Punctured Test SNR -1.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -1.0 with ber  0.04475759342312813 with bler 0.4769600000000001
Punctured Test SNR -1.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR -0.5 with ber  0.01966159977018833 with bler 0.30047999999999997
Punctured Test SNR -0.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 0.0 with ber  0.007449397351592779 with bler 0.16522000000000006
Punctured Test SNR 0.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 0.5 with ber  0.0025304004084318876 with bler 0.08365999999999998
Punctured Test SNR 0.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 1.0 with ber  0.0009155998122878373 with bler 0.04037999999999998
Punctured Test SNR 1.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 1.5 with ber  0.00032879988430067897 with bler 0.018900000000000014
Punctured Test SNR 1.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 2.0 with ber  0.0001373999984934926 with bler 0.008560000000000005
Punctured Test SNR 2.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 2.5 with ber  5.059999966761097e-05 with bler 0.0035800000000000025
Punctured Test SNR 2.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 3.0 with ber  2.240000139863696e-05 with bler 0.0015200000000000012
Punctured Test SNR 3.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 3.5 with ber  8.999999408842996e-06 with bler 0.0006600000000000004
Punctured Test SNR 3.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 4.0 with ber  4.800000624527456e-06 with bler 0.0003400000000000002
Punctured Test SNR 4.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 4.5 with ber  2.6000000161729986e-06 with bler 0.00018
Punctured Test SNR 4.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 5.0 with ber  0.0 with bler 0.0
Punctured Test SNR 5.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 5.5 with ber  0.0 with bler 0.0
Punctured Test SNR 5.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 6.0 with ber  1.9999998812636477e-07 with bler 2e-05
Punctured Test SNR 6.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 6.5 with ber  0.0 with bler 0.0
Punctured Test SNR 6.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 7.0 with ber  0.0 with bler 0.0
Punctured Test SNR 7.0 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 7.5 with ber  0.0 with bler 0.0
Punctured Test SNR 7.5 with ber  0.0 with bler 0.0
no pos BER specified.
Test SNR 8.0 with ber  0.0 with bler 0.0
Punctured Test SNR 8.0 with ber  0.0 with bler 0.0
final results on SNRs  [-6.0, -5.5, -5.0, -4.5, -4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0]
BER [0.4193839132785797, 0.4057748019695282, 0.3900512456893921, 0.36726969480514526, 0.3388248383998871, 0.3005545735359192, 0.2530718147754669, 0.19663816690444946, 0.1387261599302292, 0.0839385986328125, 0.04475759342312813, 0.01966159977018833, 0.007449397351592779, 0.0025304004084318876, 0.0009155998122878373, 0.00032879988430067897, 0.0001373999984934926, 5.059999966761097e-05, 2.240000139863696e-05, 8.999999408842996e-06, 4.800000624527456e-06, 2.6000000161729986e-06, 0.0, 0.0, 1.9999998812636477e-07, 0.0, 0.0, 0.0, 0.0]
BLER [1.0, 0.99996, 0.9998000000000001, 0.9993800000000003, 0.99664, 0.9879799999999999, 0.9665399999999995, 0.9137800000000007, 0.8149599999999999, 0.6616, 0.4769600000000001, 0.30047999999999997, 0.16522000000000006, 0.08365999999999998, 0.04037999999999998, 0.018900000000000014, 0.008560000000000005, 0.0035800000000000025, 0.0015200000000000012, 0.0006600000000000004, 0.0003400000000000002, 0.00018, 0.0, 0.0, 2e-05, 0.0, 0.0, 0.0, 0.0]
final results on punctured SNRs  [-6.0, -5.5, -5.0, -4.5, -4.0, -3.5, -3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0]
BER [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLER [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
encoder power is tensor(1.)
adjusted SNR should be [-5.999999783366708, -5.500000098238313, -5.000000066793477, -4.50000011295861, -4.000000187224616, -3.4999997269259646, -3.0000001853677105, -2.5000003462924134, -2.000000180303801, -1.4999997446509226, -1.0000000166986343, -0.49999973308696327, -0.0, 0.5000001308463472, 1.0000002900227403, 1.5000000201403676, 2.0000002404171053, 2.5000000877622415, 3.0000002493010487, 3.500000207085638, 3.999999717024358, 4.500000386779476, 4.999999888090176, 5.499999992104031, 6.0000004906757844, 6.4999998602371445, 7.000000126534256, 7.49999978449592, 7.999999988978487]
